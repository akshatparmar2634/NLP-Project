{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "from random import shuffle, sample\n",
    "import os\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>messages</th>\n",
       "      <th>sender_labels</th>\n",
       "      <th>receiver_labels</th>\n",
       "      <th>speakers</th>\n",
       "      <th>receivers</th>\n",
       "      <th>absolute_message_index</th>\n",
       "      <th>relative_message_index</th>\n",
       "      <th>seasons</th>\n",
       "      <th>years</th>\n",
       "      <th>game_score</th>\n",
       "      <th>game_score_delta</th>\n",
       "      <th>players</th>\n",
       "      <th>game_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Germany!\\n\\nJust the person I want to speak w...</td>\n",
       "      <td>[True, True, True, True, True, True, True, Tru...</td>\n",
       "      <td>[True, True, True, True, NOANNOTATION, NOANNOT...</td>\n",
       "      <td>[italy, germany, italy, germany, italy, italy,...</td>\n",
       "      <td>[germany, italy, germany, italy, germany, germ...</td>\n",
       "      <td>[74, 76, 86, 87, 89, 92, 97, 117, 119, 121, 12...</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>[Spring, Spring, Spring, Spring, Spring, Sprin...</td>\n",
       "      <td>[1901, 1901, 1901, 1901, 1901, 1901, 1901, 190...</td>\n",
       "      <td>[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[italy, germany]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Hello there! What's your general plan for thi...</td>\n",
       "      <td>[True, False, True, False, True, True, True, T...</td>\n",
       "      <td>[True, True, True, True, True, NOANNOTATION, T...</td>\n",
       "      <td>[austria, italy, austria, italy, italy, austri...</td>\n",
       "      <td>[italy, austria, italy, austria, austria, ital...</td>\n",
       "      <td>[1, 67, 71, 73, 98, 99, 101, 179, 181, 185, 18...</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>[Spring, Spring, Spring, Spring, Spring, Sprin...</td>\n",
       "      <td>[1901, 1901, 1901, 1901, 1901, 1901, 1901, 190...</td>\n",
       "      <td>[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 5, 4, 4, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 1, -1, -...</td>\n",
       "      <td>[italy, austria]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Buongiorno! \\nBe kinda nice to know if you're...</td>\n",
       "      <td>[True, True, False, True, True, True, True, Tr...</td>\n",
       "      <td>[True, False, True, False, True, True, NOANNOT...</td>\n",
       "      <td>[russia, italy, russia, italy, russia, italy, ...</td>\n",
       "      <td>[italy, russia, italy, russia, italy, russia, ...</td>\n",
       "      <td>[11, 50, 52, 57, 61, 66, 77, 85, 96, 102, 116,...</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>[Spring, Spring, Spring, Spring, Spring, Sprin...</td>\n",
       "      <td>[1901, 1901, 1901, 1901, 1901, 1901, 1901, 190...</td>\n",
       "      <td>[4, 3, 4, 3, 4, 3, 4, 3, 3, 3, 4, 3, 3, 4, 4, ...</td>\n",
       "      <td>[1, -1, 1, -1, 1, -1, 1, -1, -1, -1, 1, -1, -1...</td>\n",
       "      <td>[italy, russia]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Hey italy! good luck this game. I'm guessing ...</td>\n",
       "      <td>[True, False, True, True, True, True, True, Tr...</td>\n",
       "      <td>[NOANNOTATION, True, True, False, True, True, ...</td>\n",
       "      <td>[england, italy, england, england, england, it...</td>\n",
       "      <td>[italy, england, italy, italy, italy, england,...</td>\n",
       "      <td>[32, 95, 106, 107, 108, 110, 113, 125, 126, 12...</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>[Spring, Spring, Spring, Spring, Spring, Sprin...</td>\n",
       "      <td>[1901, 1901, 1901, 1901, 1901, 1901, 1901, 190...</td>\n",
       "      <td>[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[italy, england]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Hello Italy what’s up what are your thoughts ...</td>\n",
       "      <td>[True, False, False, True, True, True, True, T...</td>\n",
       "      <td>[NOANNOTATION, True, True, True, True, True, N...</td>\n",
       "      <td>[turkey, italy, italy, italy, turkey, italy, t...</td>\n",
       "      <td>[italy, turkey, turkey, turkey, italy, turkey,...</td>\n",
       "      <td>[45, 94, 103, 150, 154, 178, 192, 194, 195, 19...</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>[Spring, Spring, Spring, Spring, Fall, Fall, F...</td>\n",
       "      <td>[1901, 1901, 1901, 1901, 1901, 1901, 1901, 190...</td>\n",
       "      <td>[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 5, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, -1, 1...</td>\n",
       "      <td>[italy, turkey]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            messages  \\\n",
       "0  [Germany!\\n\\nJust the person I want to speak w...   \n",
       "1  [Hello there! What's your general plan for thi...   \n",
       "2  [Buongiorno! \\nBe kinda nice to know if you're...   \n",
       "3  [Hey italy! good luck this game. I'm guessing ...   \n",
       "4  [Hello Italy what’s up what are your thoughts ...   \n",
       "\n",
       "                                       sender_labels  \\\n",
       "0  [True, True, True, True, True, True, True, Tru...   \n",
       "1  [True, False, True, False, True, True, True, T...   \n",
       "2  [True, True, False, True, True, True, True, Tr...   \n",
       "3  [True, False, True, True, True, True, True, Tr...   \n",
       "4  [True, False, False, True, True, True, True, T...   \n",
       "\n",
       "                                     receiver_labels  \\\n",
       "0  [True, True, True, True, NOANNOTATION, NOANNOT...   \n",
       "1  [True, True, True, True, True, NOANNOTATION, T...   \n",
       "2  [True, False, True, False, True, True, NOANNOT...   \n",
       "3  [NOANNOTATION, True, True, False, True, True, ...   \n",
       "4  [NOANNOTATION, True, True, True, True, True, N...   \n",
       "\n",
       "                                            speakers  \\\n",
       "0  [italy, germany, italy, germany, italy, italy,...   \n",
       "1  [austria, italy, austria, italy, italy, austri...   \n",
       "2  [russia, italy, russia, italy, russia, italy, ...   \n",
       "3  [england, italy, england, england, england, it...   \n",
       "4  [turkey, italy, italy, italy, turkey, italy, t...   \n",
       "\n",
       "                                           receivers  \\\n",
       "0  [germany, italy, germany, italy, germany, germ...   \n",
       "1  [italy, austria, italy, austria, austria, ital...   \n",
       "2  [italy, russia, italy, russia, italy, russia, ...   \n",
       "3  [italy, england, italy, italy, italy, england,...   \n",
       "4  [italy, turkey, turkey, turkey, italy, turkey,...   \n",
       "\n",
       "                              absolute_message_index  \\\n",
       "0  [74, 76, 86, 87, 89, 92, 97, 117, 119, 121, 12...   \n",
       "1  [1, 67, 71, 73, 98, 99, 101, 179, 181, 185, 18...   \n",
       "2  [11, 50, 52, 57, 61, 66, 77, 85, 96, 102, 116,...   \n",
       "3  [32, 95, 106, 107, 108, 110, 113, 125, 126, 12...   \n",
       "4  [45, 94, 103, 150, 154, 178, 192, 194, 195, 19...   \n",
       "\n",
       "                              relative_message_index  \\\n",
       "0  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n",
       "1  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n",
       "2  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n",
       "3  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n",
       "4  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n",
       "\n",
       "                                             seasons  \\\n",
       "0  [Spring, Spring, Spring, Spring, Spring, Sprin...   \n",
       "1  [Spring, Spring, Spring, Spring, Spring, Sprin...   \n",
       "2  [Spring, Spring, Spring, Spring, Spring, Sprin...   \n",
       "3  [Spring, Spring, Spring, Spring, Spring, Sprin...   \n",
       "4  [Spring, Spring, Spring, Spring, Fall, Fall, F...   \n",
       "\n",
       "                                               years  \\\n",
       "0  [1901, 1901, 1901, 1901, 1901, 1901, 1901, 190...   \n",
       "1  [1901, 1901, 1901, 1901, 1901, 1901, 1901, 190...   \n",
       "2  [1901, 1901, 1901, 1901, 1901, 1901, 1901, 190...   \n",
       "3  [1901, 1901, 1901, 1901, 1901, 1901, 1901, 190...   \n",
       "4  [1901, 1901, 1901, 1901, 1901, 1901, 1901, 190...   \n",
       "\n",
       "                                          game_score  \\\n",
       "0  [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, ...   \n",
       "1  [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 5, 4, 4, ...   \n",
       "2  [4, 3, 4, 3, 4, 3, 4, 3, 3, 3, 4, 3, 3, 4, 4, ...   \n",
       "3  [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, ...   \n",
       "4  [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 5, ...   \n",
       "\n",
       "                                    game_score_delta           players  \\\n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  [italy, germany]   \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 1, -1, -...  [italy, austria]   \n",
       "2  [1, -1, 1, -1, 1, -1, 1, -1, -1, -1, 1, -1, -1...   [italy, russia]   \n",
       "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  [italy, england]   \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, -1, 1...   [italy, turkey]   \n",
       "\n",
       "   game_id  \n",
       "0        1  \n",
       "1        1  \n",
       "2        1  \n",
       "3        1  \n",
       "4        1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_json('data/train.jsonl', lines=True)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_single_message_format(gamefile):\n",
    "    messages = []\n",
    "    with open(gamefile) as inh:\n",
    "        for ln in inh:\n",
    "            conversation = json.loads(ln)\n",
    "            for msg, sender_label, receiver_label,  speaker, receiver, abs_index, rel_index, season, year, game_score, game_score_delta in zip(\n",
    "                conversation['messages'], conversation['sender_labels'], conversation['receiver_labels'], \n",
    "                conversation['speakers'], conversation['receivers'], \n",
    "                conversation['absolute_message_index'], conversation['relative_message_index'], \n",
    "                conversation['seasons'], conversation['years'], conversation['game_score'], \n",
    "                conversation['game_score_delta']):\n",
    "                \n",
    "                messages.append({\n",
    "                    'message': msg,\n",
    "                    'receiver_annotation': receiver_label,\n",
    "                    'sender_annotation': sender_label,\n",
    "                    'speaker': speaker,\n",
    "                    'receiver': receiver,\n",
    "                    'absolute_message_index': abs_index,\n",
    "                    'relative_message_index': rel_index,\n",
    "                    'season': season,\n",
    "                    'year': int(year),\n",
    "                    'game_score': int(game_score),\n",
    "                    'game_score_delta': int(game_score_delta),\n",
    "                    'game_id': conversation['game_id']\n",
    "                })\n",
    "    shuffle(messages)\n",
    "    return messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_single_messages(messages, outfile):\n",
    "    with open(outfile, \"w\") as outh:\n",
    "        for msg in messages:\n",
    "            outh.write(json.dumps(msg)+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT = \"data\"\n",
    "write_single_messages(to_single_message_format(os.path.join(ROOT, 'validation.jsonl')) , os.path.join(ROOT, 'validation_sm.jsonl'))\n",
    "write_single_messages(to_single_message_format(os.path.join(ROOT, 'train.jsonl')) , os.path.join(ROOT, 'train_sm.jsonl'))\n",
    "write_single_messages(to_single_message_format(os.path.join(ROOT, 'test.jsonl')) ,  os.path.join(ROOT, 'test_sm.jsonl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             message receiver_annotation  \\\n",
      "0  I see! Do you see an issue with me taking denm...                True   \n",
      "1                                   Okay let me know                True   \n",
      "2  Rgr.  Stand ready to support whatever you decide.                True   \n",
      "3       Sidebar- what’re you gonna do about england?        NOANNOTATION   \n",
      "4  Yea I’m here. I’m with you on that. Not cuttin...                True   \n",
      "\n",
      "   sender_annotation  score_delta  label  \n",
      "0               True            0      0  \n",
      "1               True           -1      1  \n",
      "2               True           -2      1  \n",
      "3               True           -3      1  \n",
      "4               True           -2      1  \n"
     ]
    }
   ],
   "source": [
    "# Load the JSONL data\n",
    "def load_data(file_path):\n",
    "    data = []\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            data.append(json.loads(line))\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# Preprocess the data\n",
    "def preprocess_data(df):\n",
    "    df['label'] = df['score_delta'].apply(lambda x: 1 if x < 0 else 0) \n",
    "    return df\n",
    "\n",
    "\n",
    "train_data = preprocess_data(load_data(\"data/train_sm.jsonl\"))\n",
    "test_data = preprocess_data(load_data(\"data/test_sm.jsonl\"))\n",
    "validation_data = preprocess_data(load_data(\"data/validation_sm.jsonl\"))\n",
    "\n",
    "print(train_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.6847865742429771\n",
      "Test Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.96      0.81      1901\n",
      "           1       0.40      0.05      0.10       840\n",
      "\n",
      "    accuracy                           0.68      2741\n",
      "   macro avg       0.55      0.51      0.45      2741\n",
      "weighted avg       0.61      0.68      0.59      2741\n",
      "\n",
      "Validation Accuracy: 0.7161016949152542\n",
      "Validation Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.97      0.83      1022\n",
      "           1       0.41      0.05      0.08       394\n",
      "\n",
      "    accuracy                           0.72      1416\n",
      "   macro avg       0.57      0.51      0.46      1416\n",
      "weighted avg       0.64      0.72      0.62      1416\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(max_features=500)\n",
    "X_train_text = vectorizer.fit_transform(train_data['message'])\n",
    "X_test_text = vectorizer.transform(test_data['message'])\n",
    "X_validation_text = vectorizer.transform(validation_data['message'])\n",
    "\n",
    "y_train = train_data['label']\n",
    "y_test = test_data['label']\n",
    "y_validation = validation_data['label']\n",
    "\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_text, y_train)\n",
    "\n",
    "\n",
    "y_test_pred = model.predict(X_test_text)\n",
    "print(\"Test Accuracy:\", accuracy_score(y_test, y_test_pred))\n",
    "print(\"Test Classification Report:\\n\", classification_report(y_test, y_test_pred))\n",
    "\n",
    "\n",
    "y_validation_pred = model.predict(X_validation_text)\n",
    "print(\"Validation Accuracy:\", accuracy_score(y_validation, y_validation_pred))\n",
    "print(\"Validation Classification Report:\\n\", classification_report(y_validation, y_validation_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jsonl_to_dataframe(jsonl_file):\n",
    "    data = []\n",
    "    with open(jsonl_file, 'r') as file:\n",
    "        for line in file:\n",
    "            data.append(json.loads(line))\n",
    "    return pd.DataFrame(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>receiver_annotation</th>\n",
       "      <th>sender_annotation</th>\n",
       "      <th>speaker</th>\n",
       "      <th>receiver</th>\n",
       "      <th>absolute_message_index</th>\n",
       "      <th>relative_message_index</th>\n",
       "      <th>season</th>\n",
       "      <th>year</th>\n",
       "      <th>game_score</th>\n",
       "      <th>game_score_delta</th>\n",
       "      <th>game_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Thoughts on builds?</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>france</td>\n",
       "      <td>england</td>\n",
       "      <td>345</td>\n",
       "      <td>87</td>\n",
       "      <td>Spring</td>\n",
       "      <td>1902</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Yup. Gonna head east/south now. Gotta eliminat...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>germany</td>\n",
       "      <td>france</td>\n",
       "      <td>891</td>\n",
       "      <td>76</td>\n",
       "      <td>Winter</td>\n",
       "      <td>1907</td>\n",
       "      <td>8</td>\n",
       "      <td>-2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>So would I, Italy! I think I'm going to focus ...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>france</td>\n",
       "      <td>italy</td>\n",
       "      <td>88</td>\n",
       "      <td>1</td>\n",
       "      <td>Fall</td>\n",
       "      <td>1901</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Anonymity is tough to keep up with the discord...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>france</td>\n",
       "      <td>germany</td>\n",
       "      <td>1079</td>\n",
       "      <td>110</td>\n",
       "      <td>Spring</td>\n",
       "      <td>1905</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>It would appear that way</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>germany</td>\n",
       "      <td>england</td>\n",
       "      <td>134</td>\n",
       "      <td>8</td>\n",
       "      <td>Fall</td>\n",
       "      <td>1901</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             message receiver_annotation  \\\n",
       "0                                Thoughts on builds?                True   \n",
       "1  Yup. Gonna head east/south now. Gotta eliminat...                True   \n",
       "2  So would I, Italy! I think I'm going to focus ...               False   \n",
       "3  Anonymity is tough to keep up with the discord...                True   \n",
       "4                           It would appear that way                True   \n",
       "\n",
       "   sender_annotation  speaker receiver  absolute_message_index  \\\n",
       "0               True   france  england                     345   \n",
       "1               True  germany   france                     891   \n",
       "2              False   france    italy                      88   \n",
       "3               True   france  germany                    1079   \n",
       "4               True  germany  england                     134   \n",
       "\n",
       "   relative_message_index  season  year  game_score  game_score_delta  game_id  \n",
       "0                      87  Spring  1902           5                 1        1  \n",
       "1                      76  Winter  1907           8                -2        7  \n",
       "2                       1    Fall  1901           3                 0        8  \n",
       "3                     110  Spring  1905           5                 0        1  \n",
       "4                       8    Fall  1901           3                 0        5  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = jsonl_to_dataframe('data/train_sm.jsonl')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Rishi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Rishi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading GloVe embeddings...\n",
      "Loading FastText embeddings...\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import emoji\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import gensim.downloader as api\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Load GloVe and FastText embeddings outside the class\n",
    "print(\"Loading GloVe embeddings...\")\n",
    "glove_vectors = api.load('glove-wiki-gigaword-100')\n",
    "print(\"Loading FastText embeddings...\")\n",
    "fasttext_vectors = api.load('fasttext-wiki-news-subwords-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\Rishi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Completed fit_transform with method: glove\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt_tab') ## This shouldn't be here but the code isn't working without it\n",
    "import torch\n",
    "\n",
    "class DataProcessor:\n",
    "    def __init__(self, dataframe, glove_vectors, fasttext_vectors):\n",
    "        self.df = dataframe\n",
    "        self.stop_words = set(stopwords.words('english'))\n",
    "        self.glove_vectors = glove_vectors\n",
    "        self.fasttext_vectors = fasttext_vectors\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    def preprocess_text(self, text):\n",
    "        # Remove emojis\n",
    "        text = emoji.replace_emoji(text, replace='')\n",
    "        # Remove punctuation\n",
    "        text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "        # Remove stop words and extra spaces\n",
    "        text = ' '.join([word for word in word_tokenize(text.lower()) if word not in self.stop_words])\n",
    "        return text\n",
    "\n",
    "    def preprocess_dataset(self):\n",
    "        self.df['cleaned_message'] = self.df['message'].apply(self.preprocess_text)\n",
    "\n",
    "    def vectorize(self, method='tfidf'):\n",
    "        if method == 'tfidf':\n",
    "            vectorizer = TfidfVectorizer()\n",
    "            vectors = vectorizer.fit_transform(self.df['cleaned_message'])\n",
    "        elif method == 'glove':\n",
    "            vectors = self._get_embeddings(self.df['cleaned_message'], self.glove_vectors)\n",
    "        elif method == 'fasttext':\n",
    "            vectors = self._get_embeddings(self.df['cleaned_message'], self.fasttext_vectors)\n",
    "        elif method == 'bert':\n",
    "            vectors = self._get_bert_embeddings(self.df['cleaned_message'])\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported vectorization method\")\n",
    "        return vectors\n",
    "\n",
    "    def _get_bert_embeddings(self, texts):\n",
    "        from transformers import BertTokenizer, BertModel\n",
    "        \n",
    "        # Load pre-trained BERT model and tokenizer\n",
    "        tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "        model = BertModel.from_pretrained('bert-base-uncased').to(self.device)\n",
    "        \n",
    "        # Tokenize and get BERT embeddings\n",
    "        encoded_inputs = tokenizer(\n",
    "            texts.tolist(),\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            return_tensors='pt',\n",
    "            max_length=512\n",
    "        ).to(self.device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = model(**encoded_inputs)\n",
    "            # Use the [CLS] token representation as the sentence embedding\n",
    "            embeddings = outputs.last_hidden_state[:, 0, :].cpu().numpy()\n",
    "        \n",
    "        return embeddings\n",
    "\n",
    "    def _get_embeddings(self, texts, embedding_model, max_length=50):\n",
    "        embeddings = []\n",
    "        for text in texts:\n",
    "            tokens = word_tokenize(text)\n",
    "            text_embeddings = []\n",
    "            for token in tokens[:max_length]:\n",
    "                try:\n",
    "                    embedding = embedding_model[token]\n",
    "                except KeyError:\n",
    "                    embedding = np.zeros(embedding_model.vector_size)\n",
    "                text_embeddings.append(embedding)\n",
    "            if len(text_embeddings) < max_length:\n",
    "                padding = [np.zeros(embedding_model.vector_size)] * (max_length - len(text_embeddings))\n",
    "                text_embeddings.extend(padding)\n",
    "            embeddings.append(np.array(text_embeddings))\n",
    "        return np.array(embeddings)\n",
    "\n",
    "    def fit_transform(self, vectorization_method='tfidf'):\n",
    "        self.preprocess_dataset()\n",
    "        vectors = self.vectorize(method=vectorization_method)\n",
    "        print(\"\\nCompleted fit_transform with method:\", vectorization_method)\n",
    "        return vectors\n",
    "\n",
    "# Example usage:\n",
    "processor = DataProcessor(df, glove_vectors, fasttext_vectors)\n",
    "vectors = processor.fit_transform(vectorization_method='glove')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
