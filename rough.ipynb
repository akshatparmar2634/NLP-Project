{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "from random import shuffle, sample\n",
    "import os\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>messages</th>\n",
       "      <th>sender_labels</th>\n",
       "      <th>receiver_labels</th>\n",
       "      <th>speakers</th>\n",
       "      <th>receivers</th>\n",
       "      <th>absolute_message_index</th>\n",
       "      <th>relative_message_index</th>\n",
       "      <th>seasons</th>\n",
       "      <th>years</th>\n",
       "      <th>game_score</th>\n",
       "      <th>game_score_delta</th>\n",
       "      <th>players</th>\n",
       "      <th>game_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Germany!\\n\\nJust the person I want to speak w...</td>\n",
       "      <td>[True, True, True, True, True, True, True, Tru...</td>\n",
       "      <td>[True, True, True, True, NOANNOTATION, NOANNOT...</td>\n",
       "      <td>[italy, germany, italy, germany, italy, italy,...</td>\n",
       "      <td>[germany, italy, germany, italy, germany, germ...</td>\n",
       "      <td>[74, 76, 86, 87, 89, 92, 97, 117, 119, 121, 12...</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>[Spring, Spring, Spring, Spring, Spring, Sprin...</td>\n",
       "      <td>[1901, 1901, 1901, 1901, 1901, 1901, 1901, 190...</td>\n",
       "      <td>[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[italy, germany]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Hello there! What's your general plan for thi...</td>\n",
       "      <td>[True, False, True, False, True, True, True, T...</td>\n",
       "      <td>[True, True, True, True, True, NOANNOTATION, T...</td>\n",
       "      <td>[austria, italy, austria, italy, italy, austri...</td>\n",
       "      <td>[italy, austria, italy, austria, austria, ital...</td>\n",
       "      <td>[1, 67, 71, 73, 98, 99, 101, 179, 181, 185, 18...</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>[Spring, Spring, Spring, Spring, Spring, Sprin...</td>\n",
       "      <td>[1901, 1901, 1901, 1901, 1901, 1901, 1901, 190...</td>\n",
       "      <td>[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 5, 4, 4, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 1, -1, -...</td>\n",
       "      <td>[italy, austria]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Buongiorno! \\nBe kinda nice to know if you're...</td>\n",
       "      <td>[True, True, False, True, True, True, True, Tr...</td>\n",
       "      <td>[True, False, True, False, True, True, NOANNOT...</td>\n",
       "      <td>[russia, italy, russia, italy, russia, italy, ...</td>\n",
       "      <td>[italy, russia, italy, russia, italy, russia, ...</td>\n",
       "      <td>[11, 50, 52, 57, 61, 66, 77, 85, 96, 102, 116,...</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>[Spring, Spring, Spring, Spring, Spring, Sprin...</td>\n",
       "      <td>[1901, 1901, 1901, 1901, 1901, 1901, 1901, 190...</td>\n",
       "      <td>[4, 3, 4, 3, 4, 3, 4, 3, 3, 3, 4, 3, 3, 4, 4, ...</td>\n",
       "      <td>[1, -1, 1, -1, 1, -1, 1, -1, -1, -1, 1, -1, -1...</td>\n",
       "      <td>[italy, russia]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Hey italy! good luck this game. I'm guessing ...</td>\n",
       "      <td>[True, False, True, True, True, True, True, Tr...</td>\n",
       "      <td>[NOANNOTATION, True, True, False, True, True, ...</td>\n",
       "      <td>[england, italy, england, england, england, it...</td>\n",
       "      <td>[italy, england, italy, italy, italy, england,...</td>\n",
       "      <td>[32, 95, 106, 107, 108, 110, 113, 125, 126, 12...</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>[Spring, Spring, Spring, Spring, Spring, Sprin...</td>\n",
       "      <td>[1901, 1901, 1901, 1901, 1901, 1901, 1901, 190...</td>\n",
       "      <td>[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[italy, england]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Hello Italy what’s up what are your thoughts ...</td>\n",
       "      <td>[True, False, False, True, True, True, True, T...</td>\n",
       "      <td>[NOANNOTATION, True, True, True, True, True, N...</td>\n",
       "      <td>[turkey, italy, italy, italy, turkey, italy, t...</td>\n",
       "      <td>[italy, turkey, turkey, turkey, italy, turkey,...</td>\n",
       "      <td>[45, 94, 103, 150, 154, 178, 192, 194, 195, 19...</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>[Spring, Spring, Spring, Spring, Fall, Fall, F...</td>\n",
       "      <td>[1901, 1901, 1901, 1901, 1901, 1901, 1901, 190...</td>\n",
       "      <td>[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 5, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, -1, 1...</td>\n",
       "      <td>[italy, turkey]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            messages  \\\n",
       "0  [Germany!\\n\\nJust the person I want to speak w...   \n",
       "1  [Hello there! What's your general plan for thi...   \n",
       "2  [Buongiorno! \\nBe kinda nice to know if you're...   \n",
       "3  [Hey italy! good luck this game. I'm guessing ...   \n",
       "4  [Hello Italy what’s up what are your thoughts ...   \n",
       "\n",
       "                                       sender_labels  \\\n",
       "0  [True, True, True, True, True, True, True, Tru...   \n",
       "1  [True, False, True, False, True, True, True, T...   \n",
       "2  [True, True, False, True, True, True, True, Tr...   \n",
       "3  [True, False, True, True, True, True, True, Tr...   \n",
       "4  [True, False, False, True, True, True, True, T...   \n",
       "\n",
       "                                     receiver_labels  \\\n",
       "0  [True, True, True, True, NOANNOTATION, NOANNOT...   \n",
       "1  [True, True, True, True, True, NOANNOTATION, T...   \n",
       "2  [True, False, True, False, True, True, NOANNOT...   \n",
       "3  [NOANNOTATION, True, True, False, True, True, ...   \n",
       "4  [NOANNOTATION, True, True, True, True, True, N...   \n",
       "\n",
       "                                            speakers  \\\n",
       "0  [italy, germany, italy, germany, italy, italy,...   \n",
       "1  [austria, italy, austria, italy, italy, austri...   \n",
       "2  [russia, italy, russia, italy, russia, italy, ...   \n",
       "3  [england, italy, england, england, england, it...   \n",
       "4  [turkey, italy, italy, italy, turkey, italy, t...   \n",
       "\n",
       "                                           receivers  \\\n",
       "0  [germany, italy, germany, italy, germany, germ...   \n",
       "1  [italy, austria, italy, austria, austria, ital...   \n",
       "2  [italy, russia, italy, russia, italy, russia, ...   \n",
       "3  [italy, england, italy, italy, italy, england,...   \n",
       "4  [italy, turkey, turkey, turkey, italy, turkey,...   \n",
       "\n",
       "                              absolute_message_index  \\\n",
       "0  [74, 76, 86, 87, 89, 92, 97, 117, 119, 121, 12...   \n",
       "1  [1, 67, 71, 73, 98, 99, 101, 179, 181, 185, 18...   \n",
       "2  [11, 50, 52, 57, 61, 66, 77, 85, 96, 102, 116,...   \n",
       "3  [32, 95, 106, 107, 108, 110, 113, 125, 126, 12...   \n",
       "4  [45, 94, 103, 150, 154, 178, 192, 194, 195, 19...   \n",
       "\n",
       "                              relative_message_index  \\\n",
       "0  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n",
       "1  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n",
       "2  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n",
       "3  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n",
       "4  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n",
       "\n",
       "                                             seasons  \\\n",
       "0  [Spring, Spring, Spring, Spring, Spring, Sprin...   \n",
       "1  [Spring, Spring, Spring, Spring, Spring, Sprin...   \n",
       "2  [Spring, Spring, Spring, Spring, Spring, Sprin...   \n",
       "3  [Spring, Spring, Spring, Spring, Spring, Sprin...   \n",
       "4  [Spring, Spring, Spring, Spring, Fall, Fall, F...   \n",
       "\n",
       "                                               years  \\\n",
       "0  [1901, 1901, 1901, 1901, 1901, 1901, 1901, 190...   \n",
       "1  [1901, 1901, 1901, 1901, 1901, 1901, 1901, 190...   \n",
       "2  [1901, 1901, 1901, 1901, 1901, 1901, 1901, 190...   \n",
       "3  [1901, 1901, 1901, 1901, 1901, 1901, 1901, 190...   \n",
       "4  [1901, 1901, 1901, 1901, 1901, 1901, 1901, 190...   \n",
       "\n",
       "                                          game_score  \\\n",
       "0  [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, ...   \n",
       "1  [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 5, 4, 4, ...   \n",
       "2  [4, 3, 4, 3, 4, 3, 4, 3, 3, 3, 4, 3, 3, 4, 4, ...   \n",
       "3  [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, ...   \n",
       "4  [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 5, ...   \n",
       "\n",
       "                                    game_score_delta           players  \\\n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  [italy, germany]   \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 1, -1, -...  [italy, austria]   \n",
       "2  [1, -1, 1, -1, 1, -1, 1, -1, -1, -1, 1, -1, -1...   [italy, russia]   \n",
       "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  [italy, england]   \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, -1, 1...   [italy, turkey]   \n",
       "\n",
       "   game_id  \n",
       "0        1  \n",
       "1        1  \n",
       "2        1  \n",
       "3        1  \n",
       "4        1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_json('data/train.jsonl', lines=True)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_single_message_format(gamefile):\n",
    "    messages = []\n",
    "    with open(gamefile) as inh:\n",
    "        for ln in inh:\n",
    "            conversation = json.loads(ln)\n",
    "            for msg, sender_label, receiver_label,  speaker, receiver, abs_index, rel_index, season, year, game_score, game_score_delta in zip(\n",
    "                conversation['messages'], conversation['sender_labels'], conversation['receiver_labels'], \n",
    "                conversation['speakers'], conversation['receivers'], \n",
    "                conversation['absolute_message_index'], conversation['relative_message_index'], \n",
    "                conversation['seasons'], conversation['years'], conversation['game_score'], \n",
    "                conversation['game_score_delta']):\n",
    "                \n",
    "                messages.append({\n",
    "                    'message': msg,\n",
    "                    'receiver_annotation': receiver_label,\n",
    "                    'sender_annotation': sender_label,\n",
    "                    'speaker': speaker,\n",
    "                    'receiver': receiver,\n",
    "                    'absolute_message_index': abs_index,\n",
    "                    'relative_message_index': rel_index,\n",
    "                    'season': season,\n",
    "                    'year': int(year),\n",
    "                    'game_score': int(game_score),\n",
    "                    'game_score_delta': int(game_score_delta),\n",
    "                    'game_id': conversation['game_id']\n",
    "                })\n",
    "    shuffle(messages)\n",
    "    return messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_single_messages(messages, outfile):\n",
    "    with open(outfile, \"w\") as outh:\n",
    "        for msg in messages:\n",
    "            outh.write(json.dumps(msg)+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT = \"data\"\n",
    "write_single_messages(to_single_message_format(os.path.join(ROOT, 'validation.jsonl')) , os.path.join(ROOT, 'validation_sm.jsonl'))\n",
    "write_single_messages(to_single_message_format(os.path.join(ROOT, 'train.jsonl')) , os.path.join(ROOT, 'train_sm.jsonl'))\n",
    "write_single_messages(to_single_message_format(os.path.join(ROOT, 'test.jsonl')) ,  os.path.join(ROOT, 'test_sm.jsonl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             message receiver_annotation  \\\n",
      "0  I see! Do you see an issue with me taking denm...                True   \n",
      "1                                   Okay let me know                True   \n",
      "2  Rgr.  Stand ready to support whatever you decide.                True   \n",
      "3       Sidebar- what’re you gonna do about england?        NOANNOTATION   \n",
      "4  Yea I’m here. I’m with you on that. Not cuttin...                True   \n",
      "\n",
      "   sender_annotation  score_delta  label  \n",
      "0               True            0      0  \n",
      "1               True           -1      1  \n",
      "2               True           -2      1  \n",
      "3               True           -3      1  \n",
      "4               True           -2      1  \n"
     ]
    }
   ],
   "source": [
    "# Load the JSONL data\n",
    "def load_data(file_path):\n",
    "    data = []\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            data.append(json.loads(line))\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# Preprocess the data\n",
    "def preprocess_data(df):\n",
    "    df['label'] = df['score_delta'].apply(lambda x: 1 if x < 0 else 0) \n",
    "    return df\n",
    "\n",
    "\n",
    "train_data = preprocess_data(load_data(\"data/train_sm.jsonl\"))\n",
    "test_data = preprocess_data(load_data(\"data/test_sm.jsonl\"))\n",
    "validation_data = preprocess_data(load_data(\"data/validation_sm.jsonl\"))\n",
    "\n",
    "print(train_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.6847865742429771\n",
      "Test Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.96      0.81      1901\n",
      "           1       0.40      0.05      0.10       840\n",
      "\n",
      "    accuracy                           0.68      2741\n",
      "   macro avg       0.55      0.51      0.45      2741\n",
      "weighted avg       0.61      0.68      0.59      2741\n",
      "\n",
      "Validation Accuracy: 0.7161016949152542\n",
      "Validation Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.97      0.83      1022\n",
      "           1       0.41      0.05      0.08       394\n",
      "\n",
      "    accuracy                           0.72      1416\n",
      "   macro avg       0.57      0.51      0.46      1416\n",
      "weighted avg       0.64      0.72      0.62      1416\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(max_features=500)\n",
    "X_train_text = vectorizer.fit_transform(train_data['message'])\n",
    "X_test_text = vectorizer.transform(test_data['message'])\n",
    "X_validation_text = vectorizer.transform(validation_data['message'])\n",
    "\n",
    "y_train = train_data['label']\n",
    "y_test = test_data['label']\n",
    "y_validation = validation_data['label']\n",
    "\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_text, y_train)\n",
    "\n",
    "\n",
    "y_test_pred = model.predict(X_test_text)\n",
    "print(\"Test Accuracy:\", accuracy_score(y_test, y_test_pred))\n",
    "print(\"Test Classification Report:\\n\", classification_report(y_test, y_test_pred))\n",
    "\n",
    "\n",
    "y_validation_pred = model.predict(X_validation_text)\n",
    "print(\"Validation Accuracy:\", accuracy_score(y_validation, y_validation_pred))\n",
    "print(\"Validation Classification Report:\\n\", classification_report(y_validation, y_validation_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jsonl_to_dataframe(jsonl_file):\n",
    "    data = []\n",
    "    with open(jsonl_file, 'r') as file:\n",
    "        for line in file:\n",
    "            data.append(json.loads(line))\n",
    "    return pd.DataFrame(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>receiver_annotation</th>\n",
       "      <th>sender_annotation</th>\n",
       "      <th>speaker</th>\n",
       "      <th>receiver</th>\n",
       "      <th>absolute_message_index</th>\n",
       "      <th>relative_message_index</th>\n",
       "      <th>season</th>\n",
       "      <th>year</th>\n",
       "      <th>game_score</th>\n",
       "      <th>game_score_delta</th>\n",
       "      <th>game_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Thoughts on builds?</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>france</td>\n",
       "      <td>england</td>\n",
       "      <td>345</td>\n",
       "      <td>87</td>\n",
       "      <td>Spring</td>\n",
       "      <td>1902</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Yup. Gonna head east/south now. Gotta eliminat...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>germany</td>\n",
       "      <td>france</td>\n",
       "      <td>891</td>\n",
       "      <td>76</td>\n",
       "      <td>Winter</td>\n",
       "      <td>1907</td>\n",
       "      <td>8</td>\n",
       "      <td>-2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>So would I, Italy! I think I'm going to focus ...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>france</td>\n",
       "      <td>italy</td>\n",
       "      <td>88</td>\n",
       "      <td>1</td>\n",
       "      <td>Fall</td>\n",
       "      <td>1901</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Anonymity is tough to keep up with the discord...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>france</td>\n",
       "      <td>germany</td>\n",
       "      <td>1079</td>\n",
       "      <td>110</td>\n",
       "      <td>Spring</td>\n",
       "      <td>1905</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>It would appear that way</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>germany</td>\n",
       "      <td>england</td>\n",
       "      <td>134</td>\n",
       "      <td>8</td>\n",
       "      <td>Fall</td>\n",
       "      <td>1901</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             message receiver_annotation  \\\n",
       "0                                Thoughts on builds?                True   \n",
       "1  Yup. Gonna head east/south now. Gotta eliminat...                True   \n",
       "2  So would I, Italy! I think I'm going to focus ...               False   \n",
       "3  Anonymity is tough to keep up with the discord...                True   \n",
       "4                           It would appear that way                True   \n",
       "\n",
       "   sender_annotation  speaker receiver  absolute_message_index  \\\n",
       "0               True   france  england                     345   \n",
       "1               True  germany   france                     891   \n",
       "2              False   france    italy                      88   \n",
       "3               True   france  germany                    1079   \n",
       "4               True  germany  england                     134   \n",
       "\n",
       "   relative_message_index  season  year  game_score  game_score_delta  game_id  \n",
       "0                      87  Spring  1902           5                 1        1  \n",
       "1                      76  Winter  1907           8                -2        7  \n",
       "2                       1    Fall  1901           3                 0        8  \n",
       "3                     110  Spring  1905           5                 0        1  \n",
       "4                       8    Fall  1901           3                 0        5  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = jsonl_to_dataframe('data/train_sm.jsonl')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Rishi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Rishi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading GloVe embeddings...\n",
      "Loading FastText embeddings...\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import emoji\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import gensim.downloader as api\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Load GloVe and FastText embeddings outside the class\n",
    "print(\"Loading GloVe embeddings...\")\n",
    "glove_vectors = api.load('glove-wiki-gigaword-100')\n",
    "print(\"Loading FastText embeddings...\")\n",
    "fasttext_vectors = api.load('fasttext-wiki-news-subwords-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\Rishi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Completed fit_transform with method: glove\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt_tab') ## This shouldn't be here but the code isn't working without it\n",
    "import torch\n",
    "\n",
    "class DataProcessor:\n",
    "    def __init__(self, dataframe, glove_vectors, fasttext_vectors):\n",
    "        self.df = dataframe\n",
    "        self.stop_words = set(stopwords.words('english'))\n",
    "        self.glove_vectors = glove_vectors\n",
    "        self.fasttext_vectors = fasttext_vectors\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    def preprocess_text(self, text):\n",
    "        # Remove emojis\n",
    "        text = emoji.replace_emoji(text, replace='')\n",
    "        # Remove punctuation\n",
    "        text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "        # Remove stop words and extra spaces\n",
    "        text = ' '.join([word for word in word_tokenize(text.lower()) if word not in self.stop_words])\n",
    "        return text\n",
    "\n",
    "    def preprocess_dataset(self):\n",
    "        self.df['cleaned_message'] = self.df['message'].apply(self.preprocess_text)\n",
    "\n",
    "    def vectorize(self, method='tfidf'):\n",
    "        if method == 'tfidf':\n",
    "            vectorizer = TfidfVectorizer()\n",
    "            vectors = vectorizer.fit_transform(self.df['cleaned_message'])\n",
    "        elif method == 'glove':\n",
    "            vectors = self._get_embeddings(self.df['cleaned_message'], self.glove_vectors)\n",
    "        elif method == 'fasttext':\n",
    "            vectors = self._get_embeddings(self.df['cleaned_message'], self.fasttext_vectors)\n",
    "        elif method == 'bert':\n",
    "            vectors = self._get_bert_embeddings(self.df['cleaned_message'])\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported vectorization method\")\n",
    "        return vectors\n",
    "\n",
    "    def _get_bert_embeddings(self, texts):\n",
    "        from transformers import BertTokenizer, BertModel\n",
    "        \n",
    "        # Load pre-trained BERT model and tokenizer\n",
    "        tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "        model = BertModel.from_pretrained('bert-base-uncased').to(self.device)\n",
    "        \n",
    "        # Tokenize and get BERT embeddings\n",
    "        encoded_inputs = tokenizer(\n",
    "            texts.tolist(),\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            return_tensors='pt',\n",
    "            max_length=512\n",
    "        ).to(self.device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = model(**encoded_inputs)\n",
    "            # Use the [CLS] token representation as the sentence embedding\n",
    "            embeddings = outputs.last_hidden_state[:, 0, :].cpu().numpy()\n",
    "        \n",
    "        return embeddings\n",
    "\n",
    "    def _get_embeddings(self, texts, embedding_model, max_length=50):\n",
    "        embeddings = []\n",
    "        for text in texts:\n",
    "            tokens = word_tokenize(text)\n",
    "            text_embeddings = []\n",
    "            for token in tokens[:max_length]:\n",
    "                try:\n",
    "                    embedding = embedding_model[token]\n",
    "                except KeyError:\n",
    "                    embedding = np.zeros(embedding_model.vector_size)\n",
    "                text_embeddings.append(embedding)\n",
    "            if len(text_embeddings) < max_length:\n",
    "                padding = [np.zeros(embedding_model.vector_size)] * (max_length - len(text_embeddings))\n",
    "                text_embeddings.extend(padding)\n",
    "            embeddings.append(np.array(text_embeddings))\n",
    "        return np.array(embeddings)\n",
    "\n",
    "    def fit_transform(self, vectorization_method='tfidf'):\n",
    "        self.preprocess_dataset()\n",
    "        vectors = self.vectorize(method=vectorization_method)\n",
    "        print(\"\\nCompleted fit_transform with method:\", vectorization_method)\n",
    "        return vectors\n",
    "\n",
    "# Example usage:\n",
    "processor = DataProcessor(df, glove_vectors, fasttext_vectors)\n",
    "vectors = processor.fit_transform(vectorization_method='glove')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sentiment_polarity  avg_sentence_length  avg_word_length  type_token_ratio  \\\n",
      "0            0.321429                 18.0         3.500000          0.888889   \n",
      "1            0.650000                  4.0         3.416667          0.916667   \n",
      "2           -0.194444                  9.0         5.111111          1.000000   \n",
      "3            0.000000                  0.0         0.000000          0.000000   \n",
      "4           -0.312500                  5.5         4.181818          1.000000   \n",
      "\n",
      "   function_word_count  pronoun_usage  third_person_pronoun_count  \\\n",
      "0                    2              2                           0   \n",
      "1                    4              1                           0   \n",
      "2                    2              0                           0   \n",
      "3                    0              0                           0   \n",
      "4                    2              1                           0   \n",
      "\n",
      "   flesch_reading_ease  flesch_kincaid_grade  comma_count  ...  \\\n",
      "0                87.05                   5.6            0  ...   \n",
      "1                84.68                   4.4            0  ...   \n",
      "2                45.42                   9.2            0  ...   \n",
      "3               206.84                 -15.7            0  ...   \n",
      "4                78.25                   4.8            0  ...   \n",
      "\n",
      "   sender_annotation  speaker  receiver  absolute_message_index  \\\n",
      "0               True    italy   austria                    1215   \n",
      "1               True  england     italy                     335   \n",
      "2               True    italy   england                     225   \n",
      "3               True  england   germany                    1336   \n",
      "4               True  germany     italy                    2122   \n",
      "\n",
      "   relative_message_index  season  year  game_score  game_score_delta  game_id  \n",
      "0                     301    Fall  1902           4                -1        2  \n",
      "1                      70    Fall  1901           3                 0        3  \n",
      "2                      32    Fall  1901           3                 0        3  \n",
      "3                     284    Fall  1905           6                -1        3  \n",
      "4                     260    Fall  1907           7                -3        1  \n",
      "\n",
      "[5 rows x 33 columns]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from feature_extractor import FeatureExtractor\n",
    "\n",
    "def read_jsonl(file_path):\n",
    "    \"\"\"Read messages and additional fields from a JSONL file.\"\"\"\n",
    "    data = []\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            data.append(json.loads(line))\n",
    "    return data\n",
    "\n",
    "def extract_features_from_messages(data):\n",
    "    \"\"\"Extract features from a list of messages using FeatureExtractor and include additional fields.\"\"\"\n",
    "    feature_extractor = FeatureExtractor()\n",
    "    features_list = []\n",
    "    for entry in data:\n",
    "        # Extract features from the message\n",
    "        features = feature_extractor.extract_features(entry['message'])\n",
    "        # Include additional fields as features\n",
    "        features.update({\n",
    "            'receiver_annotation': entry['receiver_annotation'],\n",
    "            'sender_annotation': entry['sender_annotation'],\n",
    "            'speaker': entry['speaker'],\n",
    "            'receiver': entry['receiver'],\n",
    "            'absolute_message_index': entry['absolute_message_index'],\n",
    "            'relative_message_index': entry['relative_message_index'],\n",
    "            'season': entry['season'],\n",
    "            'year': entry['year'],\n",
    "            'game_score': entry['game_score'],\n",
    "            'game_score_delta': entry['game_score_delta'],\n",
    "            'game_id': entry['game_id']\n",
    "        })\n",
    "        features_list.append(features)\n",
    "    return features_list\n",
    "\n",
    "def create_dataframe(features_list):\n",
    "    \"\"\"Create a pandas DataFrame from a list of feature dictionaries.\"\"\"\n",
    "    return pd.DataFrame(features_list)\n",
    "\n",
    "def process_jsonl_to_dataframe(file_path):\n",
    "    \"\"\"Process a JSONL file to a pandas DataFrame with extracted features and additional fields.\"\"\"\n",
    "    data = read_jsonl(file_path)\n",
    "    features_list = extract_features_from_messages(data)\n",
    "    df = create_dataframe(features_list)\n",
    "    return df\n",
    "\n",
    "# Example usage\n",
    "file_path = 'data/train_sm.jsonl'  # Replace with your actual file path\n",
    "df = process_jsonl_to_dataframe(file_path)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment_polarity</th>\n",
       "      <th>avg_sentence_length</th>\n",
       "      <th>avg_word_length</th>\n",
       "      <th>type_token_ratio</th>\n",
       "      <th>function_word_count</th>\n",
       "      <th>pronoun_usage</th>\n",
       "      <th>third_person_pronoun_count</th>\n",
       "      <th>flesch_reading_ease</th>\n",
       "      <th>flesch_kincaid_grade</th>\n",
       "      <th>comma_count</th>\n",
       "      <th>...</th>\n",
       "      <th>sender_annotation</th>\n",
       "      <th>speaker</th>\n",
       "      <th>receiver</th>\n",
       "      <th>absolute_message_index</th>\n",
       "      <th>relative_message_index</th>\n",
       "      <th>season</th>\n",
       "      <th>year</th>\n",
       "      <th>game_score</th>\n",
       "      <th>game_score_delta</th>\n",
       "      <th>game_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.321429</td>\n",
       "      <td>18.0</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>87.05</td>\n",
       "      <td>5.6</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>italy</td>\n",
       "      <td>austria</td>\n",
       "      <td>1215</td>\n",
       "      <td>301</td>\n",
       "      <td>Fall</td>\n",
       "      <td>1902</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.650000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.416667</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>84.68</td>\n",
       "      <td>4.4</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>england</td>\n",
       "      <td>italy</td>\n",
       "      <td>335</td>\n",
       "      <td>70</td>\n",
       "      <td>Fall</td>\n",
       "      <td>1901</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.194444</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.111111</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>45.42</td>\n",
       "      <td>9.2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>italy</td>\n",
       "      <td>england</td>\n",
       "      <td>225</td>\n",
       "      <td>32</td>\n",
       "      <td>Fall</td>\n",
       "      <td>1901</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>206.84</td>\n",
       "      <td>-15.7</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>england</td>\n",
       "      <td>germany</td>\n",
       "      <td>1336</td>\n",
       "      <td>284</td>\n",
       "      <td>Fall</td>\n",
       "      <td>1905</td>\n",
       "      <td>6</td>\n",
       "      <td>-1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.312500</td>\n",
       "      <td>5.5</td>\n",
       "      <td>4.181818</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>78.25</td>\n",
       "      <td>4.8</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>germany</td>\n",
       "      <td>italy</td>\n",
       "      <td>2122</td>\n",
       "      <td>260</td>\n",
       "      <td>Fall</td>\n",
       "      <td>1907</td>\n",
       "      <td>7</td>\n",
       "      <td>-3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.125000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>80.28</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>turkey</td>\n",
       "      <td>italy</td>\n",
       "      <td>919</td>\n",
       "      <td>42</td>\n",
       "      <td>Fall</td>\n",
       "      <td>1902</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.800000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>117.16</td>\n",
       "      <td>-1.9</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>germany</td>\n",
       "      <td>england</td>\n",
       "      <td>2975</td>\n",
       "      <td>456</td>\n",
       "      <td>Spring</td>\n",
       "      <td>1907</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.033333</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.909091</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>85.69</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>russia</td>\n",
       "      <td>italy</td>\n",
       "      <td>834</td>\n",
       "      <td>37</td>\n",
       "      <td>Winter</td>\n",
       "      <td>1906</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.550000</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.888889</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>91.61</td>\n",
       "      <td>3.8</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>france</td>\n",
       "      <td>italy</td>\n",
       "      <td>729</td>\n",
       "      <td>27</td>\n",
       "      <td>Spring</td>\n",
       "      <td>1903</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.600000</td>\n",
       "      <td>13.0</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>0.743590</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>78.08</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>austria</td>\n",
       "      <td>russia</td>\n",
       "      <td>350</td>\n",
       "      <td>44</td>\n",
       "      <td>Spring</td>\n",
       "      <td>1902</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.250000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>74.19</td>\n",
       "      <td>6.4</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>italy</td>\n",
       "      <td>germany</td>\n",
       "      <td>2579</td>\n",
       "      <td>304</td>\n",
       "      <td>Spring</td>\n",
       "      <td>1905</td>\n",
       "      <td>6</td>\n",
       "      <td>-3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.142857</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>89.75</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>germany</td>\n",
       "      <td>england</td>\n",
       "      <td>2782</td>\n",
       "      <td>396</td>\n",
       "      <td>Fall</td>\n",
       "      <td>1905</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.200000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.800000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>61.33</td>\n",
       "      <td>7.2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>england</td>\n",
       "      <td>russia</td>\n",
       "      <td>257</td>\n",
       "      <td>20</td>\n",
       "      <td>Fall</td>\n",
       "      <td>1902</td>\n",
       "      <td>5</td>\n",
       "      <td>-1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.571429</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>89.75</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>turkey</td>\n",
       "      <td>germany</td>\n",
       "      <td>885</td>\n",
       "      <td>38</td>\n",
       "      <td>Fall</td>\n",
       "      <td>1910</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>95.17</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>germany</td>\n",
       "      <td>austria</td>\n",
       "      <td>2433</td>\n",
       "      <td>368</td>\n",
       "      <td>Spring</td>\n",
       "      <td>1905</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.275000</td>\n",
       "      <td>18.0</td>\n",
       "      <td>3.972222</td>\n",
       "      <td>0.805556</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>70.13</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>italy</td>\n",
       "      <td>germany</td>\n",
       "      <td>1624</td>\n",
       "      <td>163</td>\n",
       "      <td>Fall</td>\n",
       "      <td>1906</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.0</td>\n",
       "      <td>3.812500</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>81.63</td>\n",
       "      <td>5.6</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>england</td>\n",
       "      <td>russia</td>\n",
       "      <td>385</td>\n",
       "      <td>6</td>\n",
       "      <td>Winter</td>\n",
       "      <td>1901</td>\n",
       "      <td>5</td>\n",
       "      <td>-1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.032000</td>\n",
       "      <td>18.0</td>\n",
       "      <td>3.750000</td>\n",
       "      <td>0.805556</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>78.59</td>\n",
       "      <td>6.8</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>turkey</td>\n",
       "      <td>austria</td>\n",
       "      <td>1455</td>\n",
       "      <td>62</td>\n",
       "      <td>Spring</td>\n",
       "      <td>1906</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-47.99</td>\n",
       "      <td>20.2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>germany</td>\n",
       "      <td>turkey</td>\n",
       "      <td>1142</td>\n",
       "      <td>68</td>\n",
       "      <td>Fall</td>\n",
       "      <td>1902</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-0.077778</td>\n",
       "      <td>27.0</td>\n",
       "      <td>3.629630</td>\n",
       "      <td>0.814815</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>86.37</td>\n",
       "      <td>7.9</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>austria</td>\n",
       "      <td>germany</td>\n",
       "      <td>1927</td>\n",
       "      <td>287</td>\n",
       "      <td>Spring</td>\n",
       "      <td>1904</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    sentiment_polarity  avg_sentence_length  avg_word_length  \\\n",
       "0             0.321429                 18.0         3.500000   \n",
       "1             0.650000                  4.0         3.416667   \n",
       "2            -0.194444                  9.0         5.111111   \n",
       "3             0.000000                  0.0         0.000000   \n",
       "4            -0.312500                  5.5         4.181818   \n",
       "5             0.000000                  8.0         4.125000   \n",
       "6             0.000000                  5.0         3.800000   \n",
       "7             0.033333                 11.0         3.909091   \n",
       "8             0.550000                  9.0         3.888889   \n",
       "9             0.600000                 13.0         3.333333   \n",
       "10            0.250000                  6.0         3.666667   \n",
       "11            0.000000                  3.5         4.142857   \n",
       "12            0.200000                 10.0         5.800000   \n",
       "13            0.000000                  3.5         3.571429   \n",
       "14            0.000000                 10.0         3.500000   \n",
       "15            0.275000                 18.0         3.972222   \n",
       "16            0.000000                 16.0         3.812500   \n",
       "17            0.032000                 18.0         3.750000   \n",
       "18            0.000000                  1.0         7.000000   \n",
       "19           -0.077778                 27.0         3.629630   \n",
       "\n",
       "    type_token_ratio  function_word_count  pronoun_usage  \\\n",
       "0           0.888889                    2              2   \n",
       "1           0.916667                    4              1   \n",
       "2           1.000000                    2              0   \n",
       "3           0.000000                    0              0   \n",
       "4           1.000000                    2              1   \n",
       "5           1.000000                    2              0   \n",
       "6           1.000000                    1              1   \n",
       "7           1.000000                    5              2   \n",
       "8           0.888889                   10              1   \n",
       "9           0.743590                    8              5   \n",
       "10          0.916667                    4              2   \n",
       "11          1.000000                    1              0   \n",
       "12          1.000000                    1              1   \n",
       "13          1.000000                    2              1   \n",
       "14          1.000000                    1              0   \n",
       "15          0.805556                    7              1   \n",
       "16          0.937500                    1              1   \n",
       "17          0.805556                    5              6   \n",
       "18          1.000000                    0              0   \n",
       "19          0.814815                    3              7   \n",
       "\n",
       "    third_person_pronoun_count  flesch_reading_ease  flesch_kincaid_grade  \\\n",
       "0                            0                87.05                   5.6   \n",
       "1                            0                84.68                   4.4   \n",
       "2                            0                45.42                   9.2   \n",
       "3                            0               206.84                 -15.7   \n",
       "4                            0                78.25                   4.8   \n",
       "5                            0                80.28                   4.1   \n",
       "6                            0               117.16                  -1.9   \n",
       "7                            0                85.69                   4.0   \n",
       "8                            0                91.61                   3.8   \n",
       "9                            1                78.08                   7.0   \n",
       "10                           0                74.19                   6.4   \n",
       "11                           0                89.75                   2.5   \n",
       "12                           0                61.33                   7.2   \n",
       "13                           0                89.75                   2.5   \n",
       "14                           0                95.17                   2.5   \n",
       "15                           0                70.13                   8.0   \n",
       "16                           0                81.63                   5.6   \n",
       "17                           1                78.59                   6.8   \n",
       "18                           0               -47.99                  20.2   \n",
       "19                           0                86.37                   7.9   \n",
       "\n",
       "    comma_count  ...  sender_annotation  speaker  receiver  \\\n",
       "0             0  ...               True    italy   austria   \n",
       "1             0  ...               True  england     italy   \n",
       "2             0  ...               True    italy   england   \n",
       "3             0  ...               True  england   germany   \n",
       "4             0  ...               True  germany     italy   \n",
       "5             0  ...               True   turkey     italy   \n",
       "6             0  ...               True  germany   england   \n",
       "7             1  ...               True   russia     italy   \n",
       "8             0  ...               True   france     italy   \n",
       "9             4  ...               True  austria    russia   \n",
       "10            0  ...               True    italy   germany   \n",
       "11            0  ...               True  germany   england   \n",
       "12            2  ...              False  england    russia   \n",
       "13            1  ...               True   turkey   germany   \n",
       "14            0  ...               True  germany   austria   \n",
       "15            2  ...               True    italy   germany   \n",
       "16            1  ...              False  england    russia   \n",
       "17            2  ...               True   turkey   austria   \n",
       "18            0  ...               True  germany    turkey   \n",
       "19            0  ...              False  austria   germany   \n",
       "\n",
       "    absolute_message_index  relative_message_index  season  year  game_score  \\\n",
       "0                     1215                     301    Fall  1902           4   \n",
       "1                      335                      70    Fall  1901           3   \n",
       "2                      225                      32    Fall  1901           3   \n",
       "3                     1336                     284    Fall  1905           6   \n",
       "4                     2122                     260    Fall  1907           7   \n",
       "5                      919                      42    Fall  1902           4   \n",
       "6                     2975                     456  Spring  1907          10   \n",
       "7                      834                      37  Winter  1906           4   \n",
       "8                      729                      27  Spring  1903           5   \n",
       "9                      350                      44  Spring  1902           5   \n",
       "10                    2579                     304  Spring  1905           6   \n",
       "11                    2782                     396    Fall  1905           9   \n",
       "12                     257                      20    Fall  1902           5   \n",
       "13                     885                      38    Fall  1910          11   \n",
       "14                    2433                     368  Spring  1905           9   \n",
       "15                    1624                     163    Fall  1906           8   \n",
       "16                     385                       6  Winter  1901           5   \n",
       "17                    1455                      62  Spring  1906           4   \n",
       "18                    1142                      68    Fall  1902           5   \n",
       "19                    1927                     287  Spring  1904           7   \n",
       "\n",
       "    game_score_delta  game_id  \n",
       "0                 -1        2  \n",
       "1                  0        3  \n",
       "2                  0        3  \n",
       "3                 -1        3  \n",
       "4                 -3        1  \n",
       "5                  0        9  \n",
       "6                  2        2  \n",
       "7                 -1        7  \n",
       "8                  0        3  \n",
       "9                  0       10  \n",
       "10                -3        2  \n",
       "11                 3        2  \n",
       "12                -1        5  \n",
       "13                10        8  \n",
       "14                 1        2  \n",
       "15                 3        1  \n",
       "16                -1        9  \n",
       "17                -1        3  \n",
       "18                 0        2  \n",
       "19                 0        2  \n",
       "\n",
       "[20 rows x 33 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13132, 33)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
