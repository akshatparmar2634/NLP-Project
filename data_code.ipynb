{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "from random import shuffle, sample\n",
    "import os\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "import spacy\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>messages</th>\n",
       "      <th>sender_labels</th>\n",
       "      <th>receiver_labels</th>\n",
       "      <th>speakers</th>\n",
       "      <th>receivers</th>\n",
       "      <th>absolute_message_index</th>\n",
       "      <th>relative_message_index</th>\n",
       "      <th>seasons</th>\n",
       "      <th>years</th>\n",
       "      <th>game_score</th>\n",
       "      <th>game_score_delta</th>\n",
       "      <th>players</th>\n",
       "      <th>game_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Germany!\\n\\nJust the person I want to speak w...</td>\n",
       "      <td>[True, True, True, True, True, True, True, Tru...</td>\n",
       "      <td>[True, True, True, True, NOANNOTATION, NOANNOT...</td>\n",
       "      <td>[italy, germany, italy, germany, italy, italy,...</td>\n",
       "      <td>[germany, italy, germany, italy, germany, germ...</td>\n",
       "      <td>[74, 76, 86, 87, 89, 92, 97, 117, 119, 121, 12...</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>[Spring, Spring, Spring, Spring, Spring, Sprin...</td>\n",
       "      <td>[1901, 1901, 1901, 1901, 1901, 1901, 1901, 190...</td>\n",
       "      <td>[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[italy, germany]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Hello there! What's your general plan for thi...</td>\n",
       "      <td>[True, False, True, False, True, True, True, T...</td>\n",
       "      <td>[True, True, True, True, True, NOANNOTATION, T...</td>\n",
       "      <td>[austria, italy, austria, italy, italy, austri...</td>\n",
       "      <td>[italy, austria, italy, austria, austria, ital...</td>\n",
       "      <td>[1, 67, 71, 73, 98, 99, 101, 179, 181, 185, 18...</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>[Spring, Spring, Spring, Spring, Spring, Sprin...</td>\n",
       "      <td>[1901, 1901, 1901, 1901, 1901, 1901, 1901, 190...</td>\n",
       "      <td>[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 5, 4, 4, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 1, -1, -...</td>\n",
       "      <td>[italy, austria]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Buongiorno! \\nBe kinda nice to know if you're...</td>\n",
       "      <td>[True, True, False, True, True, True, True, Tr...</td>\n",
       "      <td>[True, False, True, False, True, True, NOANNOT...</td>\n",
       "      <td>[russia, italy, russia, italy, russia, italy, ...</td>\n",
       "      <td>[italy, russia, italy, russia, italy, russia, ...</td>\n",
       "      <td>[11, 50, 52, 57, 61, 66, 77, 85, 96, 102, 116,...</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>[Spring, Spring, Spring, Spring, Spring, Sprin...</td>\n",
       "      <td>[1901, 1901, 1901, 1901, 1901, 1901, 1901, 190...</td>\n",
       "      <td>[4, 3, 4, 3, 4, 3, 4, 3, 3, 3, 4, 3, 3, 4, 4, ...</td>\n",
       "      <td>[1, -1, 1, -1, 1, -1, 1, -1, -1, -1, 1, -1, -1...</td>\n",
       "      <td>[italy, russia]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Hey italy! good luck this game. I'm guessing ...</td>\n",
       "      <td>[True, False, True, True, True, True, True, Tr...</td>\n",
       "      <td>[NOANNOTATION, True, True, False, True, True, ...</td>\n",
       "      <td>[england, italy, england, england, england, it...</td>\n",
       "      <td>[italy, england, italy, italy, italy, england,...</td>\n",
       "      <td>[32, 95, 106, 107, 108, 110, 113, 125, 126, 12...</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>[Spring, Spring, Spring, Spring, Spring, Sprin...</td>\n",
       "      <td>[1901, 1901, 1901, 1901, 1901, 1901, 1901, 190...</td>\n",
       "      <td>[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[italy, england]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Hello Italy what’s up what are your thoughts ...</td>\n",
       "      <td>[True, False, False, True, True, True, True, T...</td>\n",
       "      <td>[NOANNOTATION, True, True, True, True, True, N...</td>\n",
       "      <td>[turkey, italy, italy, italy, turkey, italy, t...</td>\n",
       "      <td>[italy, turkey, turkey, turkey, italy, turkey,...</td>\n",
       "      <td>[45, 94, 103, 150, 154, 178, 192, 194, 195, 19...</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>[Spring, Spring, Spring, Spring, Fall, Fall, F...</td>\n",
       "      <td>[1901, 1901, 1901, 1901, 1901, 1901, 1901, 190...</td>\n",
       "      <td>[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 5, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, -1, 1...</td>\n",
       "      <td>[italy, turkey]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            messages  \\\n",
       "0  [Germany!\\n\\nJust the person I want to speak w...   \n",
       "1  [Hello there! What's your general plan for thi...   \n",
       "2  [Buongiorno! \\nBe kinda nice to know if you're...   \n",
       "3  [Hey italy! good luck this game. I'm guessing ...   \n",
       "4  [Hello Italy what’s up what are your thoughts ...   \n",
       "\n",
       "                                       sender_labels  \\\n",
       "0  [True, True, True, True, True, True, True, Tru...   \n",
       "1  [True, False, True, False, True, True, True, T...   \n",
       "2  [True, True, False, True, True, True, True, Tr...   \n",
       "3  [True, False, True, True, True, True, True, Tr...   \n",
       "4  [True, False, False, True, True, True, True, T...   \n",
       "\n",
       "                                     receiver_labels  \\\n",
       "0  [True, True, True, True, NOANNOTATION, NOANNOT...   \n",
       "1  [True, True, True, True, True, NOANNOTATION, T...   \n",
       "2  [True, False, True, False, True, True, NOANNOT...   \n",
       "3  [NOANNOTATION, True, True, False, True, True, ...   \n",
       "4  [NOANNOTATION, True, True, True, True, True, N...   \n",
       "\n",
       "                                            speakers  \\\n",
       "0  [italy, germany, italy, germany, italy, italy,...   \n",
       "1  [austria, italy, austria, italy, italy, austri...   \n",
       "2  [russia, italy, russia, italy, russia, italy, ...   \n",
       "3  [england, italy, england, england, england, it...   \n",
       "4  [turkey, italy, italy, italy, turkey, italy, t...   \n",
       "\n",
       "                                           receivers  \\\n",
       "0  [germany, italy, germany, italy, germany, germ...   \n",
       "1  [italy, austria, italy, austria, austria, ital...   \n",
       "2  [italy, russia, italy, russia, italy, russia, ...   \n",
       "3  [italy, england, italy, italy, italy, england,...   \n",
       "4  [italy, turkey, turkey, turkey, italy, turkey,...   \n",
       "\n",
       "                              absolute_message_index  \\\n",
       "0  [74, 76, 86, 87, 89, 92, 97, 117, 119, 121, 12...   \n",
       "1  [1, 67, 71, 73, 98, 99, 101, 179, 181, 185, 18...   \n",
       "2  [11, 50, 52, 57, 61, 66, 77, 85, 96, 102, 116,...   \n",
       "3  [32, 95, 106, 107, 108, 110, 113, 125, 126, 12...   \n",
       "4  [45, 94, 103, 150, 154, 178, 192, 194, 195, 19...   \n",
       "\n",
       "                              relative_message_index  \\\n",
       "0  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n",
       "1  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n",
       "2  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n",
       "3  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n",
       "4  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n",
       "\n",
       "                                             seasons  \\\n",
       "0  [Spring, Spring, Spring, Spring, Spring, Sprin...   \n",
       "1  [Spring, Spring, Spring, Spring, Spring, Sprin...   \n",
       "2  [Spring, Spring, Spring, Spring, Spring, Sprin...   \n",
       "3  [Spring, Spring, Spring, Spring, Spring, Sprin...   \n",
       "4  [Spring, Spring, Spring, Spring, Fall, Fall, F...   \n",
       "\n",
       "                                               years  \\\n",
       "0  [1901, 1901, 1901, 1901, 1901, 1901, 1901, 190...   \n",
       "1  [1901, 1901, 1901, 1901, 1901, 1901, 1901, 190...   \n",
       "2  [1901, 1901, 1901, 1901, 1901, 1901, 1901, 190...   \n",
       "3  [1901, 1901, 1901, 1901, 1901, 1901, 1901, 190...   \n",
       "4  [1901, 1901, 1901, 1901, 1901, 1901, 1901, 190...   \n",
       "\n",
       "                                          game_score  \\\n",
       "0  [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, ...   \n",
       "1  [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 5, 4, 4, ...   \n",
       "2  [4, 3, 4, 3, 4, 3, 4, 3, 3, 3, 4, 3, 3, 4, 4, ...   \n",
       "3  [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, ...   \n",
       "4  [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 5, ...   \n",
       "\n",
       "                                    game_score_delta           players  \\\n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  [italy, germany]   \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 1, -1, -...  [italy, austria]   \n",
       "2  [1, -1, 1, -1, 1, -1, 1, -1, -1, -1, 1, -1, -1...   [italy, russia]   \n",
       "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  [italy, england]   \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, -1, 1...   [italy, turkey]   \n",
       "\n",
       "   game_id  \n",
       "0        1  \n",
       "1        1  \n",
       "2        1  \n",
       "3        1  \n",
       "4        1  "
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_json('data/train.jsonl', lines=True)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_single_message_format(gamefile):\n",
    "    messages = []\n",
    "    with open(gamefile) as inh:\n",
    "        for ln in inh:\n",
    "            conversation = json.loads(ln)\n",
    "            for msg, sender_label, receiver_label, score_delta \\\n",
    "                in zip(conversation['messages'],conversation['sender_labels'], \\\n",
    "                    conversation['receiver_labels'], conversation['game_score_delta']):\n",
    "                messages.append({'message': msg, 'receiver_annotation': receiver_label,\\\n",
    "                    'sender_annotation':sender_label, 'score_delta': int(score_delta)})\n",
    "    shuffle(messages)    \n",
    "    return messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_single_messages(messages, outfile):\n",
    "    with open(outfile, \"w\") as outh:\n",
    "        for msg in messages:\n",
    "            outh.write(json.dumps(msg)+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT = \"data\"\n",
    "write_single_messages(to_single_message_format(os.path.join(ROOT, 'validation.jsonl')) , os.path.join(ROOT, 'validation_sm.jsonl'))\n",
    "write_single_messages(to_single_message_format(os.path.join(ROOT, 'train.jsonl')) , os.path.join(ROOT, 'train_sm.jsonl'))\n",
    "write_single_messages(to_single_message_format(os.path.join(ROOT, 'test.jsonl')) ,  os.path.join(ROOT, 'test_sm.jsonl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             message  sender_annotation\n",
      "0  I think me and England are really on the same ...                  1\n",
      "1  He got pretty lucky in the opening - some of t...                  1\n",
      "2  I wish I could say \"what can I do to help you,...                  1\n",
      "3  Haha yeah that was kind of my thinking. Russia...                  1\n",
      "4  Damn.\\n\\nYeah, can do. Hopefully if we can sec...                  1\n"
     ]
    }
   ],
   "source": [
    "def load_data(file_path):\n",
    "    data = []\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            data.append(json.loads(line))\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# Preprocess data\n",
    "def preprocess_data(df):\n",
    "    df = df[['message', 'sender_annotation']].copy()\n",
    "    df['sender_annotation'] = df['sender_annotation'].astype(int)\n",
    "    return df\n",
    "\n",
    "train_data = preprocess_data(load_data(\"data/train_sm.jsonl\"))\n",
    "test_data = preprocess_data(load_data(\"data/test_sm.jsonl\"))\n",
    "validation_data = preprocess_data(load_data(\"data/validation_sm.jsonl\"))\n",
    "\n",
    "print(train_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorizer = TfidfVectorizer(max_features=500)\n",
    "# X_train_text = vectorizer.fit_transform(train_data['message'])\n",
    "# X_test_text = vectorizer.transform(test_data['message'])\n",
    "# X_validation_text = vectorizer.transform(validation_data['message'])\n",
    "\n",
    "# y_train = train_data['label']\n",
    "# y_test = test_data['label']\n",
    "# y_validation = validation_data['label']\n",
    "\n",
    "\n",
    "# model = LogisticRegression()\n",
    "# model.fit(X_train_text, y_train)\n",
    "\n",
    "\n",
    "# y_test_pred = model.predict(X_test_text)\n",
    "# print(\"Test Accuracy:\", accuracy_score(y_test, y_test_pred))\n",
    "# print(\"Test Classification Report:\\n\", classification_report(y_test, y_test_pred))\n",
    "\n",
    "\n",
    "# y_validation_pred = model.predict(X_validation_text)\n",
    "# print(\"Validation Accuracy:\", accuracy_score(y_validation, y_validation_pred))\n",
    "# print(\"Validation Classification Report:\\n\", classification_report(y_validation, y_validation_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_glove_embeddings(glove_path, embedding_dim=200):\n",
    "    word_to_vec = {}\n",
    "    with open(glove_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            vector = np.asarray(values[1:], dtype=np.float32)\n",
    "            word_to_vec[word] = vector\n",
    "    return word_to_vec\n",
    "\n",
    "glove_path = \"glove.6B/glove.6B.300d.txt\"\n",
    "glove_embeddings = load_glove_embeddings(glove_path, embedding_dim=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def tokenize_text(text):\n",
    "    return [token.text.lower() for token in nlp(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQ_LEN = 50\n",
    "\n",
    "def convert_text_to_embedding(text, glove_embeddings, embedding_dim=300, max_seq_len=100):\n",
    "    tokens = text.split()\n",
    "    embeddings = [glove_embeddings[word] if word in glove_embeddings else np.zeros(embedding_dim) for word in tokens]\n",
    "\n",
    "\n",
    "    if len(embeddings) > max_seq_len:\n",
    "        embeddings = embeddings[:max_seq_len]\n",
    "    else:\n",
    "        embeddings += [np.zeros(embedding_dim)] * (max_seq_len - len(embeddings))\n",
    "\n",
    "    return np.array(embeddings, dtype=np.float32)\n",
    "\n",
    "\n",
    "train_data['embeddings'] = train_data['message'].apply(lambda x: convert_text_to_embedding(x, glove_embeddings))\n",
    "test_data['embeddings'] = test_data['message'].apply(lambda x: convert_text_to_embedding(x, glove_embeddings))\n",
    "validation_data['embeddings'] = validation_data['message'].apply(lambda x: convert_text_to_embedding(x, glove_embeddings))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MessageDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.embeddings = torch.tensor(np.stack(df['embeddings'].values), dtype=torch.float32)\n",
    "        self.labels = torch.tensor(df['sender_annotation'].values, dtype=torch.float32)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.embeddings[idx], self.labels[idx]\n",
    "\n",
    "\n",
    "train_dataset = MessageDataset(train_data)\n",
    "test_dataset = MessageDataset(test_data)\n",
    "validation_dataset = MessageDataset(validation_data)\n",
    "\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "val_loader = DataLoader(validation_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "class BiLSTMClassifier(nn.Module):\n",
    "    def __init__(self, input_size=300, hidden_size=100, dropout=0.5):\n",
    "        super(BiLSTMClassifier, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True, bidirectional=True)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc = nn.Linear(hidden_size * 2, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        lstm_out, _ = self.lstm(x)  \n",
    "        pooled = torch.max(lstm_out, dim=1)[0]\n",
    "        dropped = self.dropout(pooled)\n",
    "        output = self.fc(dropped)\n",
    "        return self.sigmoid(output).squeeze(1)\n",
    "\n",
    "# Instantiate the model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = BiLSTMClassifier().to(device)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "posclass_weight = 30.0\n",
    "loss_fn = nn.BCELoss(weight=torch.tensor([posclass_weight], device=device))\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|██████████| 411/411 [00:02<00:00, 182.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 5.8168, Val Loss = 5.3074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 100%|██████████| 411/411 [00:02<00:00, 186.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss = 5.6022, Val Loss = 5.2371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: 100%|██████████| 411/411 [00:02<00:00, 193.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss = 5.4826, Val Loss = 5.2327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: 100%|██████████| 411/411 [00:02<00:00, 197.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Train Loss = 5.3827, Val Loss = 5.2063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: 100%|██████████| 411/411 [00:02<00:00, 188.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Train Loss = 5.2557, Val Loss = 5.2251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10: 100%|██████████| 411/411 [00:01<00:00, 216.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Train Loss = 5.1074, Val Loss = 5.1993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: 100%|██████████| 411/411 [00:02<00:00, 186.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: Train Loss = 4.8555, Val Loss = 5.3862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10: 100%|██████████| 411/411 [00:02<00:00, 199.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: Train Loss = 4.7002, Val Loss = 5.3599\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10: 100%|██████████| 411/411 [00:02<00:00, 201.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: Train Loss = 4.6019, Val Loss = 5.3762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|██████████| 411/411 [00:02<00:00, 196.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: Train Loss = 4.4002, Val Loss = 5.5010\n"
     ]
    }
   ],
   "source": [
    "NUM_EPOCHS = 10\n",
    "PATIENCE = 5\n",
    "\n",
    "def train_model(model, train_loader, val_loader, optimizer, loss_fn, num_epochs=NUM_EPOCHS):\n",
    "    best_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        \n",
    "        for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
    "            inputs, labels = batch\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "        \n",
    "        avg_train_loss = total_loss / len(train_loader)\n",
    "        \n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                inputs, labels = batch\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = loss_fn(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "        \n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        print(f\"Epoch {epoch+1}: Train Loss = {avg_train_loss:.4f}, Val Loss = {avg_val_loss:.4f}\")\n",
    "\n",
    "    torch.save(model.state_dict(), \"test_lstm_model.pth\")\n",
    "\n",
    "train_model(model, train_loader, val_loader, optimizer, loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vimal\\AppData\\Local\\Temp\\ipykernel_12348\\591331045.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"best_lstm_model.pth\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9084\n",
      "Macro F1-score: 0.4951\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"best_lstm_model.pth\"))\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "\n",
    "        outputs = model(inputs)\n",
    "\n",
    "\n",
    "        predicted = (outputs > 0.5).float()\n",
    "\n",
    "\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "\n",
    "accuracy = correct / total\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "\n",
    "f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "print(f\"Macro F1-score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
